+++
date = "2022-09-15"
title = "logistic regression in R: a tutorial"
categories = [ "posts", "tutorials" ]
tags = [ "statistics", "logistic regression" ]
+++

logistic regression is a statistical method for modelling a binary response; it is a popular way to classify your samples and to assess which predictor variables are significant. here, i will demonstrate a simple example of how to implement a logistic regressin in R.

the [dataset] we will use is found in the R's "Stat2Data" package. according to the documentation, this dataset contains information e.g., GPA, MCAT scores, etc, gathered on 55 medical school applicants from a liberal arts college in the US.

improtant points about logistic regression:

- in logistic regression, we are regressing the binary response variables on the explanatory variables, which could either be quantitative (e.g. GPA), categorical, or binary (e.g. sex). 
- logistic regression is exactly the same as linear regression except it uses logit transformation. the former uses the least-squares method to fit the line while the latter uses maximum likelihood to fit
- in logistic regression we are not predicting 0 and 1 directly, but the proportion (maxmimum likelihood) of 1's.

![alternate text](/img/logitequation.png)

we will model med school acceptance, which is a binary response (y/n) using explanatory variables including GPA, MCAT scores and gender.

## step 1 install and import the dataset

```install.packages("Stat2Data")
library(Stat2Data)
data("MedGPA")
names(MedGPA)
```
you may take a look at the variables by using the names function.

## step 2 building a model for acceptance (0/1) using gpa

here i will show you why using linear regression does not work here. to build a linear model, you could use the in-built function ```lm```, specify the formula, and save that in a variable called ```lm1```. you could add a line to it where "acceptance" takes values of 0s and 1s only.

```plot(Acceptance ~ GPA, data = MedGPA)
lm1 = lm(Acceptance ~ GPA, data = MedGPA)
abline(lm1)
```
![alternate text](/img/step2.png)

examine the plot. the predicted acceptance looks messy, it could be 0.6, 0.3, 0 or even 1. in other words, it could go beyond 1, and below 0 infinitely. this is not reasonable, you could not predict acceptance (0/1) on axes that exceed the (0,1) range. therefore, we need to transform the axes using the logit function such that it would stay within the range. let's build a logistic regression model.

## step 3.1 building a logistic regression model to predict acceptance using GPA
now we build a logistic regression model using the ```glm``` function

```glm(Acceptance~GPA, data = MedGPA, family = binomial)```

![alternate text](/img/step3.1.png)

this model outputs numerical values for the y-intercept and the slope, such that if you plug any number into the "GPA" term in the equation and solve for p: log(p/1-p)= -19.207 + 5.454 * GPA, you could predict the proportion/likelihood of the acceptance. For example, try to solve the equation when GPA = 3. The answer is the probability of getting accepted is 5.6%.

## step 3.2 about the "odds" ratio and the coefficients"

odds = probability of success (1) / probability of failure. now if we consider in terms of log(odds) = -19.207 + 5.454*GPA, we could interpret the coefficients as: "as GPA goes up by 1, the log(odds) increases by 5.454, or when GPA goes up by 1, the "odds" of acceptance increases by the exponentiated number 5.454, which is 233. 

## step 4 how to predict acceptance using GPA and MCAT scores and sex?

```glm2 = glm(Acceptance ~ GPA + MCAT + Sex, data = MedGPA, family = binomial)
summary(glm2)
coef(glm2)
exp(coef(glm2)) # in terms of chance, or odds
```

![alternate text](/img/step4.1.png)

now looking at the summary of the mode, the exp of GPA coefficient is 170. this means that controlling the MCAT and sex of the student, as the student's GPA goes up by 1, the odds of the student being admitted will increase by a factor of 170

![alternate text](/img/step4.2.png)

## step 5 comparing models

```
glm0 = glm(Acceptance ~ 1, data = MedGPA, family= binomial)
glm2 = glm(Acceptance ~ GPA + MCAT + Sex, data = MedGPA, family = binomial)
anova(glm0, glm2, test= "Chisq")
```

![alternate text](/img/step5.1.png)

now we could compare the modes, we do this to check if model 2 indeed has very significant predictors or not. from the results you could see that indeed it is significant, meaning the predictors in model 2- at least some of them are significant.

```
glm1 = glm(Acceptance~GPA, data = MedGPA, family = binomial)
glm2 = glm(Acceptance ~ GPA + MCAT + Sex, data = MedGPA, family = binomial)
anova(glm1, glm2, test = "Chisq")
```
![alternate text](/img/step5.2.png)

here you see the *p*-value is a little bit smaller than 0.5. this means model 2 is better than model 1, we reject the first model here, and thinking, maybe at least one fo the two variables (MCAT or sex) here is significant.

[dataset]: https://rdrr.io/cran/Stat2Data/man/MedGPA.html